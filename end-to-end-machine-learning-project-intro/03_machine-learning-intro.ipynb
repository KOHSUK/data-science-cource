{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanicデータセットを用いた機械学習入門"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"./assets/RMS_Titanic_3.jpg\"  width=\"600px\" alt=\"https://commons.wikimedia.org/wiki/File:RMS_Titanic_3.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、データサイエンスや機械学習を学ぶものの多くが通る道である、Titanicデータセットを用いたデータ分析を行っていく。\n",
    "\n",
    "もちろんタイタニックは、映画「タイタニック」で有名なあの船。\n",
    "\n",
    "> タイタニック（英語: RMS Titanic、ロイヤルメールシップ・タイタニック）は、20世紀初頭に建造されたイギリス船籍のオーシャン・ライナー。\n",
    "> ホワイト・スター・ライン社が保有するオリンピック級客船の2番船であったが、処女航海中の1912年4月14日深夜に氷山に衝突し、その際の損傷による浸水が原因となって翌15日未明に沈没した。([wikipediaより](https://ja.wikipedia.org/wiki/%E3%82%BF%E3%82%A4%E3%82%BF%E3%83%8B%E3%83%83%E3%82%AF_(%E5%AE%A2%E8%88%B9)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset について"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic datasetは色々なところでフリーのデータセットとして公開されている。\n",
    "- Kaggle (https://www.kaggle.com/competitions/titanic)\n",
    "- Tensorflow Datasets (https://www.tensorflow.org/datasets/catalog/titanic?hl=en)\n",
    "- Seaborn Datasets (https://github.com/mwaskom/seaborn-data)\n",
    "などなど\n",
    "\n",
    "今回は、 Kaggleのものを利用する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習プロジェクトの一般的な流れ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 分析の目的と問題設定\n",
    "2. データを取得する\n",
    "3. EDA ~ データからインサイトを得る ~\n",
    "4. 前処理 ~ データクレンジングとフィーチャーエンジニアリング ~\n",
    "5. モデルの作成、学習、推論の実行\n",
    "<br>↑今回はここまで\n",
    "6. モデルのファインチューニング\n",
    "7. 結果の提示\n",
    "8. システムに組み込む"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを取得する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "早速データを取得してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('https://raw.githubusercontent.com/KOHSUK/data-science-cource/master/datasets/titanic/test.csv')\n",
    "train_set = pd.read_csv('https://raw.githubusercontent.com/KOHSUK/data-science-cource/master/datasets/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを頭から数行だけ見てみる\n",
    "train_set.head() # head(10)とすると10行取得できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:', train_set.columns)\n",
    "print('test:', test_set.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_setには`Survived`が存在しない。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各列の説明はこの通り\n",
    "\n",
    "| 列名 | 説明 |\n",
    "|------|------|\n",
    "| PassengerId | 乗客のID |\n",
    "| Survived | 生存したか否か (0 = No, 1 = Yes) |\n",
    "| Pclass | チケットのクラス (1 = 1st, 2 = 2nd, 3 = 3rd) |\n",
    "| Name | 乗客の名前 |\n",
    "| Sex | 性別 |\n",
    "| Age | 年齢 |\n",
    "| SibSp | タイタニック号に乗船していた兄弟/配偶者の数 |\n",
    "| Parch | タイタニック号に乗船していた親/子供の数 |\n",
    "| Ticket | チケット番号 |\n",
    "| Fare | 旅客運賃 |\n",
    "| Cabin | キャビン番号 |\n",
    "| Embarked | 乗船港 (C = Cherbourg, Q = Queenstown, S = Southampton) |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_setのデータを用いて、各列の情報からSurvivedを予測するモデルを作成する。\n",
    "\n",
    "test_setのデータのそれぞれの行のSurvivedの結果を予測する。\n",
    "\n",
    "という流れになる。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意点\n",
    "\n",
    "Kaggle の test.csvの真の答えは、Kaggleが持っていて、Kaggle上で予測結果を提出することでしか、最終的な予測の精度は測れない（Web上に答えは転がっているだろうが)。\n",
    "\n",
    "ここでは、train.csvの一部のデータ(例えば全体の20%)を答えがわからないふりをして傍に置いておき、\n",
    "\n",
    "もう一方のデータを使って学習、とっておいたデータ(から真の`Survived`を排除したデータ)で予測を行い、精度を測ることにする。\n",
    "\n",
    "以下はそのために、データを分けている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(train_set, test_size=0.2)\n",
    "\n",
    "# Survived列のみを取り出したデータを作成する\n",
    "test_survived = test_data[[\"Survived\"]]\n",
    "# Survived列のみを削除したデータを作成する\n",
    "test_data = test_data.drop('Survived', axis=1)\n",
    "\n",
    "# 処理結果を表示して、意図通りの列ができているか確認する。\n",
    "print('train_data:', train_data.columns)\n",
    "print()\n",
    "print('test_data:', test_data.columns)\n",
    "print()\n",
    "print('test_survived:', test_survived.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、\n",
    "\n",
    "train_data ・・・ 学習用のデータ<br>\n",
    "test_data ・・・ 検証用のデータ<br>\n",
    "test_survived ・・・ 検証用のデータの答え(Survived)\n",
    "\n",
    "に分けることができた。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA ~ データからインサイトを得る ~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここから実際に、分析を行っていく。\n",
    "\n",
    "まずは、学習用データの中身がどのようなものなのか改めて確認していく。\n",
    "\n",
    "基本として注目する点は、\n",
    "\n",
    "1. データ自体のを眺める\n",
    "2. 欠損値の確認\n",
    "3. データの特徴を把握する\n",
    "4. 異常値(外れ値)の有無\n",
    "5. 数値列間の相関係数\n",
    "6. その他ドメイン知識や仮説に基づいたデータの探索\n",
    "\n",
    "ちなみに、データの特徴を掴み、モデル作成のインサイトを得るためにデータをさまざまな角度から見ていくことを、<br>\n",
    "EDA（Explanatory Data Analysis, 探索データ分析）という。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データ自体を眺める"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの中身を少し眺める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみにtrain_data自体のデータ型を調べると、、、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandasというライブラリの`DataFrame`という型となっている。\n",
    "\n",
    "<公式のドキュメント><br>\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットのサイズを確認する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame.shape　で　`(行数, 列数)`という出力を得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 欠損値の確認\n",
    "\n",
    "データの中には何らかの理由で、特定の列の値が取得できない場合がある。\n",
    "\n",
    "その場合、データセットの中に`欠損値`が存在することになる。\n",
    "\n",
    "例えば、`Age`(年齢)列に欠損値がある場合、そのままでは全体の平均年齢を求めることはできない。\n",
    "\n",
    "よって、欠損値がデータセットに含まれるのかどうかは大きな問題となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各列の欠損値の数の合計を求める\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age`, `Cabin`, `Embarked`については、欠損値が含まれるので何らかの対処をしなければならないことがわかった。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. データの特徴を把握する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 各列のデータ型を確認する\n",
    "\n",
    "`DataFrame.dtypes`で各列のデータ型を確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`int64`, `float64`は数値データ\n",
    "`object`はPythonのobject型。String(文字列)はobjectの一種。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数値データの基本統計量を確認する\n",
    "\n",
    "`DataFrame.describe()`で各数値列の基本統計量を自動的に計算してくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値以外についても`describe`を呼ぶと、最頻値などを確認できる。\n",
    "\n",
    "例えば、`Fare`を確認すると、中央値(50%)が14前後に対して平均が30くらい、<br>\n",
    "最大値は75%点の31くらいから大きく開いて500をこえる値となっている。\n",
    "\n",
    "`Fare`に外れ値が存在することを疑うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(exclude='number')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カテゴリ値確認する\n",
    "\n",
    "データの説明などからどれがカテゴリデータかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全て文字列に変換してから、`describe()`を呼ぶと数値データについてもカテゴリ値かどうか確認できる\n",
    "train_data.astype('str').describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unique`行の数値が少ないものはカテゴリ値の場合が多い。\n",
    "\n",
    "今回は、`Survived`, `Pclass`, `Sex`, `Parch`, `Embarked`は明らかにカテゴリ値。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 異常値(外れ値)を確認する\n",
    "\n",
    "異常値(外れ値)は、分析結果に大きな影響を与える。\n",
    "\n",
    "データを可視化することで異常値に気づきやすくなる。\n",
    "\n",
    "以下では例として、`describe()`で確認した時に外れ値を疑った`Fare`のヒストグラムを描画してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(train_data['Fare'], kde=True, rug=False, bins=10)\n",
    "plt.title('Fare')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['Fare'] > 400].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "異常値、外れ値が何らかの想定外が起こった結果（入力ミスとか計測器の故障とか）であれば、\n",
    "\n",
    "- その行自体を学習データから省く\n",
    "- 何か別のデータに置き換える\n",
    "\n",
    "などの処理を行う必要がある。\n",
    "\n",
    "一方で、外れ値になっていること自体に意味がある場合もある。\n",
    "\n",
    "例えばここでは、先に「運賃を多く払っているものは優先的に救命ボートに乗っているのではないか」という仮説を検証する必要がある。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. その他ドメイン知識や仮説に基づいたデータの探索"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 仮説「運賃を多く払っているものは優先的に救命ボートに乗っているのではないか」を検証する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをコピーしておく\n",
    "check = train_data.copy()\n",
    "\n",
    "# 運賃を10ごとのカテゴリ値に変換した列を作成する(`// 10`は10で割った時の整数値でそれに10を掛けると10ごとのカテゴリになる)\n",
    "# 例：　167 // 10 * 10 = 16 * 10 = 160\n",
    "check['FareCat'] = check['Fare'] // 10 * 10\n",
    "# 列数カウント用ダミー値\n",
    "check['Count'] = 1\n",
    "\n",
    "# 運賃カテゴリごとの生存率を求める\n",
    "fare_survived = check.groupby('FareCat').agg({'Survived': 'mean', 'Count': 'sum'})\n",
    "\n",
    "fare_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fareが70未満のものは生存率が低いことがわかる。\n",
    "\n",
    "人数に差があるので一口では言えないが、運賃によって生存率が変わると言えるかもしれない。\n",
    "\n",
    "高い運賃を払える人は社会的階級が高く、救命ボートに優先的に乗せられた（のかもしれない）。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### チケットの等級ごとに生存率を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_survived = check.groupby('Pclass').agg({'Survived': 'mean', 'Count': 'sum'})\n",
    "pclass_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "明らかにチケットの等級の高いものの生存率が高い。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 性別、年齢で生存率が変わるのか確認する\n",
    "\n",
    "Wikipediaのタイタニックのページには、「[ライトラーは一等船客の「女性と子供を優先する」ことを遵守した](https://ja.wikipedia.org/wiki/%E3%82%BF%E3%82%A4%E3%82%BF%E3%83%8B%E3%83%83%E3%82%AF_(%E5%AE%A2%E8%88%B9)#:~:text=%E3%83%A9%E3%82%A4%E3%83%88%E3%83%A9%E3%83%BC%E3%81%AF%E4%B8%80%E7%AD%89%E8%88%B9%E5%AE%A2%E3%81%AE%E3%80%8C%E5%A5%B3%E6%80%A7%E3%81%A8%E5%AD%90%E4%BE%9B%E3%82%92%E5%84%AA%E5%85%88%E3%81%99%E3%82%8B%E3%80%8D%E3%81%93%E3%81%A8%E3%82%92%E9%81%B5%E5%AE%88%E3%81%97%E3%81%9F)」との記載がある。\n",
    "\n",
    "データ上その事実が読み取れるのか確認してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別ごとの生存率\n",
    "sex_survived = check.groupby('Sex').agg({'Survived': 'mean', 'Count': 'sum'})\n",
    "sex_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "圧倒的に女性の生存率が高い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年齢カテゴリを作成\n",
    "check['AgeCat'] = check['Age'] // 10 * 10\n",
    "\n",
    "age_survived = check.groupby('AgeCat').agg({'Survived': 'mean', 'Count': 'sum'})\n",
    "age_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10歳未満の子供は生存率が高いことがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 両方まとめて集計してみる\n",
    "age_sex_survived = check.groupby(['AgeCat', 'Sex']).agg({'Survived': 'mean', 'Count': 'sum'})\n",
    "age_sex_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 仮説「敬称によって生存率が異なる」\n",
    "\n",
    "時代的にも敬称は地位を表すことがあるため、`Name`列の敬称に何が使われているかを利用できるかもしれない。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_substring(big_string, substrings):\n",
    "    # check if any substring is present in the big string\n",
    "    big_string = str(big_string)\n",
    "    matches = [substring for substring in substrings if substring in big_string]\n",
    "\n",
    "    # return the first matching substring, or np.nan if none found\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                    'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                    'Don', 'Jonkheer']\n",
    "\n",
    "check['Title'] = train_data['Name'].map(lambda x: find_matching_substring(x, title_list))\n",
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値のチェック\n",
    "check['Title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敬称ごとの生存率を集計する\n",
    "title_survived = check.groupby('Title').agg({'Survived': 'mean', \"Count\": 'sum'})\n",
    "title_survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "男性につける敬称のうち、`Dr`, `Master`, `Mr`を比べると、\n",
    "\n",
    "`Master` > `Dr` > `Mr` の順に生存率が高いことがわかる。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips: 率を平均(mean)で求める理由\n",
    "\n",
    "先ほどから、生存率を求める計算方法に'mean'(平均)を指定している。\n",
    "\n",
    "これは生存したか否かの列`Survived`が0, 1の2値であることを利用している。\n",
    "\n",
    "生存率を求める方法は、\n",
    "\n",
    "$$\n",
    "    生存率 = \\frac{Survived=1の数}{全体の人数}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "一方で、`Survived`が0, 1の2値であるときのSurvivedの平均は\n",
    "\n",
    "$$\n",
    "    Survivedの平均 = \\frac{全行のSurvived(0,1)の合計}{行数}\n",
    "$$\n",
    "\n",
    "であり、データの一行一行が一人一人の人なので、`行数`は`全体の人数`と同値だし、<br>\n",
    "0 or 1 をとるデータの合計は1の数を数えているのと同じである。\n",
    "\n",
    "よって、\n",
    "\n",
    "$$\n",
    "    Survivedの平均 = \\frac{全行のSurvived(0,1)の合計}{行数} = \\frac{Survived=1の数}{全体の人数} = 生存率\n",
    "$$\n",
    "\n",
    "と言える。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理 ~ データクレンジングとフィーチャーエンジニアリング ~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は実際に、データを使って機械学習モデルを学習させるための前準備として、データの処理を行っていきます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テストデータと訓練データを結合する。\n",
    "\n",
    "まず、テストデータ(test_data)と訓練データ(train_data)を結合します。\n",
    "また、後で分割が容易になるように元々テストデータなのかどうかのフラグ列も追加します(`isTest` 0: テストデータではない、1: テストデータである)\n",
    "\n",
    "せっかく最初の時点で、分割したものをなぜまた結合するのかと思うだろうが、<br>\n",
    "こうすることで、例えば欠損値を埋める処理を`train_data`と`test_data`の2回行う必要がなくなるなど、<br>\n",
    "前処理を都合よく行うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'isTest'\n",
    "\n",
    "# 以下のようにすることで、全行に1(または0)を入れることができる。\n",
    "test_data[col_name] = 1\n",
    "train_data[col_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isTestに意図通りの値が入っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataとtest_dataを結合する\n",
    "\n",
    "dat = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行数を確認して結合ができているか確認する(shapeは(行数, 列数)なので、shape[0]は行数を取得できる)\n",
    "print(\"train_data + test_data\", train_data.shape[0] + test_data.shape[0])\n",
    "print(\"dat\", dat.shape[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 欠損値の処理\n",
    "\n",
    "`Age`, `Cabin`, `Embarked`に欠損値があるため、何らかの処理をする必要があります。\n",
    "\n",
    "欠損値の処理方法は、利用するモデルやデータの性質などによる。\n",
    "\n",
    "ここでは、`Age`は中央値、`Embarked`は最頻値で欠損値を埋めることにする。\n",
    "\n",
    "簡単にするため、`Cabin`は推論に用いないことにし、欠損値はそのままにしておくことにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = dat['Age'].mean()\n",
    "top_embarked = dat[['Embarked']].describe(exclude='number').at['top', 'Embarked']\n",
    "\n",
    "print(mean_age)\n",
    "print(top_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれ欠損値を埋める(fillnaを用いる)\n",
    "dat['Age'].fillna(mean_age, inplace=True)\n",
    "dat['Embarked'].fillna(top_embarked, inplace=True)\n",
    "\n",
    "# 確認する\n",
    "dat[['Age', 'Embarked']].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 異常値の処理\n",
    "\n",
    "異常値もここで処理をすることになる。\n",
    "\n",
    "`Fare`に外れ値が含まれることがわかっているが、等級が生存率に影響を与えていることがわかっているため、\n",
    "\n",
    "今回は特に処理を行わないことにする。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 敬称を特徴量に加える\n",
    "\n",
    "先ほど、敬称ごとに生存率に差が出る可能性があるとわかったため、それを特徴量に含める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Title'] = dat['Name'].map(lambda x: find_matching_substring(x, title_list))\n",
    "dat[['Title']].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カテゴリ値の変換\n",
    "\n",
    "多くの機械学習モデルで、文字列データより数値データが好ましい場合がある。（文字列で問題ないモデルもあるが）\n",
    "\n",
    "また、カテゴリ値をダミー変数とする方が良い場合、しなくても良い場合などさまざまではある。\n",
    "\n",
    "そのあたりは、モデルやデータの性質によるのだが、\n",
    "\n",
    "ここでは`pandas.get_dummies`を用いてダミー変数に変換してみる。\n",
    "\n",
    "ダミー変数とは？<br>\n",
    "https://bellcurve.jp/statistics/glossary/1538.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.get_dummies(dat, drop_first=True, columns=['Sex', 'Embarked', 'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な列\n",
    "\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成、学習、推論の実行"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値や外れ値の処理をし、新しい特徴量を作成したので、\n",
    "早速モデルを作成し、学習・推論して結果を見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理をしたデータを、 学習データ、学習データの教師データ、検証データに分ける。\n",
    "\n",
    "train = dat[dat['isTest'] == 0].copy()\n",
    "test = dat[dat['isTest'] ==1 ].copy()\n",
    "\n",
    "columns = ['Pclass', 'Age', 'SibSp', 'Parch',\n",
    "       'Fare', 'Sex_male', 'Embarked_Q',\n",
    "       'Embarked_S', 'Title_Col', 'Title_Countess', 'Title_Don', 'Title_Dr',\n",
    "       'Title_Jonkheer', 'Title_Major', 'Title_Master', 'Title_Miss',\n",
    "       'Title_Mlle', 'Title_Mme', 'Title_Mr', 'Title_Mrs', 'Title_Ms',\n",
    "       'Title_Rev']\n",
    "\n",
    "X_train = train[columns]\n",
    "y_train = train['Survived']\n",
    "X_test = test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests を利用する\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ハイパーパラメータは一旦適当な値にしている\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, n_jobs=-1, random_state=79)\n",
    "\n",
    "# 学習を行う\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで学習が完了！\n",
    "\n",
    "このモデルを使って推論をしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解率を求めると、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_survived['Survived'], y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-cource",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
